# 提案：接入 Claude Sonnet LLM 模型

## 概述

本提案旨在将 Claude Sonnet LLM 模型集成到用户生命周期运营管理平台中，替换现有的 Gemini API，并为智能工作流生成和用户运营对话提供更强大的 AI 能力。

## 问题陈述

### 当前状态
- ✅ 平台使用 Gemini API (`gemini-3-pro-preview`) 作为 LLM 服务
- ✅ 支持 AI 辅助生成 BPMN 工作流，通过 Function Calling 直接操作编辑器
- ✅ 现有实现在 `packages/client/src/services/llmService.ts` 中
- ✅ 支持的功能：文本生成、Function Calling、流式响应

### 核心问题

#### 问题 1：模型能力不足
**现象**：Gemini 在流程图布局能力存在明显不足，生成的 BPMN 工作流质量不理想
**影响**：用户需要大量手动调整，AI 辅助效率低
**证据**：用户反馈和内部测试显示布局质量评分 < 3.5/5.0

#### 问题 2：API 稳定性问题
**现象**：当前使用的第三方代理服务（aicodewith.com）可能存在可用性问题
**影响**：服务中断影响用户体验，错误率较高
**证据**：API 错误率 > 2%，偶发超时和连接失败

#### 问题 3：功能扩展受限
**现象**：需要更强大的 AI 能力支持用户运营对话和个性化推荐，但 Gemini 能力有限
**影响**：无法实现 AI Agent 对话功能，限制平台智能化能力
**证据**：产品规划中的"用户运营 AI 助手"功能无法落地

#### 问题 4：成本优化缺失
**现象**：缺少 Prompt Caching 等成本优化机制，API 调用成本较高
**影响**：随着用户增长，成本线性上升，难以规模化
**证据**：单次工作流生成成本 > $0.08，无缓存机制

### 解决方案目标

1. **替换 LLM 提供商**：用 Claude Sonnet 替换 Gemini，提升 AI 能力
2. **智能工作流生成**：利用 Claude 更强的代码和结构化输出能力生成高质量 BPMN 工作流
3. **用户运营对话**：为生命周期运营平台添加 AI Agent 对话功能，提供智能客服和推荐
4. **成本优化**：利用 Claude 的 Prompt Caching 功能降低 API 调用成本

## 范围定义

### 功能范围

#### 核心功能（必须实现）

1. **Claude API 集成**
   - ✅ 接入 Claude Sonnet API（通过 aicodewith.com 代理）
   - ✅ 实现 Claude API 客户端（替换现有 Gemini 实现）
   - ✅ 支持 Claude 的消息格式和认证机制
   - ✅ 实现错误处理和重试机制

2. **Function Calling 支持**
   - ✅ 支持 Claude 的 Tool Use（Function Calling）
   - ✅ 转换现有工具定义（`llmTools.ts`）为 Claude 格式
   - ✅ 实现工具执行循环（多轮工具调用）
   - ✅ 保持与现有 BPMN 编辑器工具的兼容性

3. **流式响应**
   - ✅ 支持流式响应（SSE）
   - ✅ 实现 Claude SSE 事件解析
   - ✅ 实时更新 UI（首个 token 延迟 < 500ms）

4. **对话管理**
   - ✅ 实现对话历史管理（支持多轮对话）
   - ✅ 对话上下文裁剪（处理长对话）
   - ✅ 添加与 AI 的对话输入框 UI

5. **成本优化**
   - ✅ 集成 Prompt Caching（System Prompt 和 Tools 定义）
   - ✅ 实现缓存监控和统计
   - ✅ 目标：缓存命中率 > 60%，成本降低 > 30%

6. **提示词优化**
   - ✅ 更新 `editorSystemPrompt.ts` 适配 Claude
   - ✅ 更新 `bpmnSystemPrompt.ts` 和 `xpmnSystemPrompt.ts`
   - ✅ 优化提示词结构和风格

7. **用户运营 AI Agent**
   - ✅ 添加 AI Agent 聊天界面 UI 组件
   - ✅ 集成生命周期运营数据上下文
   - ✅ 实现智能推荐工具（推荐流程模板、分析用户行为等）
   - ✅ 为生命周期运营添加 AI 推荐和决策支持

#### 技术范围

- ✅ **接口适配**：不用适配现有 LLM 服务接口（直接替换实现）
- ✅ **代码重构**：完全移除 Gemini 相关代码，使用 Claude 实现
- ✅ **前端实现**：所有功能在前端实现，不依赖后端服务

### 明确排除

- ❌ **多模型支持**：不保留 Gemini API，不支持多模型切换
- ❌ **本地部署**：不实现本地模型部署，仅使用云端 API
- ❌ **多媒体能力**：不支持语音和图像能力，仅文本交互
- ❌ **后端服务**：不实现后端 LLM 服务，前端直接调用 API
- ❌ **模型切换 UI**：不提供用户选择模型的界面

## 影响的规范

### 新增规范
- **ai-integration**：AI 集成能力规范，定义 LLM 服务接口、Tool Use、对话管理

### 修改规范
- **workflow-editor**：添加 Claude 驱动的智能工作流生成需求
- **user-lifecycle**：添加 AI Agent 对话和智能推荐需求

### 删除规范
无

## 依赖关系

### 前置依赖
- ✅ 现有 LLM 服务架构（`llmService.ts`、`llmTools.ts`）
- ✅ 用户生命周期运营基础（已完成）
- ✅ BPMN 编辑器和工作流执行引擎

### 后续依赖
无，本变更为独立功能增强

## 风险和缓解

### 风险
1. **成本增加**：Claude API 可能比 Gemini 更昂贵
   - **缓解**：使用 Prompt Caching、优化提示词长度、实现请求频率限制

2. **响应速度**：Claude 可能比 Gemini 慢
   - **缓解**：实现流式响应，提升用户体验；添加加载状态和进度提示

3. **第三方代理可用性**：依赖 aicodewith.com 服务稳定性
   - **缓解**：实现错误重试机制、降级策略、API Key 轮换

4. **API 格式差异**：Claude API 格式与 Gemini 不同，需要重新实现
   - **缓解**：直接使用 Claude API 格式，不保留 Gemini 兼容层；参考官方文档和示例代码

### 技术债务
- 现有 Gemini 相关代码需要完全移除和替换（不考虑兼容）
- 需要重新测试所有 AI 功能
- 提示词需要针对 Claude 优化

## 成功指标

### 技术指标
- ✅ Claude API 集成成功，所有功能正常工作
- ✅ Function Calling 准确率 > 95%
- ✅ 流式响应延迟 < 500ms（首个 token）
- ✅ API 错误率 < 1%
- ✅ Prompt Caching 命中率 > 60%

### 业务指标
- ✅ AI 生成工作流的质量评分 > 4.0/5.0
- ✅ 用户运营对话满意度 > 85%
- ✅ AI 推荐的点击率 > 20%
- ✅ API 成本降低 > 30%（相比优化前）

### 用户指标
- ✅ AI 功能使用率 > 50%
- ✅ 平均工作流生成时间 < 30 秒
- ✅ 对话平均轮数 > 3 轮
- ✅ 用户反馈净推荐值 (NPS) > 40

## 实施计划

### 时间估算
- **预计总时间**：2-3 周（18-23 个工作日）
- **详细任务**：见 `tasks.md`（35 个任务，5 个阶段）

### 阶段划分

#### Phase 1：核心 LLM 服务（5-6 天）
**目标**：完成 Claude API 基础集成
- Claude API 客户端实现
- 消息格式转换（Gemini → Claude）
- Function Calling 适配（Tool Use）
- 流式响应支持（SSE）
- 错误处理和重试机制
- 单元测试

#### Phase 2：工作流生成优化（3-4 天）
**目标**：确保 BPMN 工作流生成质量
- 更新提示词适配 Claude
- 测试和调优 BPMN 生成质量
- 集成测试所有编辑器工具
- 添加错误处理和降级策略

#### Phase 3：对话管理和缓存（3-4 天）
**目标**：实现对话管理和成本优化
- 对话历史管理
- 对话上下文裁剪
- Prompt Caching 集成
- 性能优化（防抖、请求队列）

#### Phase 4：用户运营 AI Agent（4-5 天）
**目标**：实现 AI Agent 对话功能
- AI Agent 聊天界面 UI
- 生命周期运营数据集成
- 智能推荐工具实现
- 系统提示词和示例对话

#### Phase 5：测试、优化和发布（3-4 天）
**目标**：确保质量和稳定性
- 端到端测试
- 性能测试和优化
- 成本监控和告警
- 文档更新
- 灰度发布

## 替代方案

### 方案 A：保留 Gemini 多模型支持（已拒绝）
**优点**：灵活性高，用户可选择模型
**缺点**：维护成本高，架构复杂，用户选择困难
**决策**：完全替换更简单直接

### 方案 B：使用 OpenRouter 统一接口（考虑中）
**优点**：支持多个 LLM，容易切换
**缺点**：额外一层抽象，可能影响性能
**决策**：如果 aicodewith.com 不支持 Claude，考虑此方案

### 方案 C：直接使用 Anthropic 官方 API（理想但受限）
**优点**：最直接稳定
**缺点**：可能有地域限制和支付问题
**决策**：优先使用代理，未来可选项

## 审批清单

- [ ] 技术架构审批：架构师确认设计合理性
- [ ] 产品审批：产品经理确认需求优先级
- [ ] 成本审批：确认 API 成本预算
- [ ] 安全审批：确认 API Key 管理和数据隐私合规

## 快速参考

### 问题总结
| 问题 | 影响 | 解决方案 |
|------|------|---------|
| 模型能力不足 | 工作流质量低 | 替换为 Claude Sonnet |
| API 稳定性差 | 错误率高 | 使用更稳定的代理服务 |
| 功能扩展受限 | 无法实现 AI Agent | 利用 Claude 更强能力 |
| 成本优化缺失 | 成本线性增长 | 集成 Prompt Caching |

### 范围总结
- **包含**：Claude API 集成、Function Calling、流式响应、对话管理、Prompt Caching、提示词优化、AI Agent UI
- **不包含**：多模型支持、本地部署、多媒体能力、后端服务

### 关键指标
- **技术**：Function Calling 准确率 > 95%，流式响应延迟 < 500ms，错误率 < 1%
- **业务**：工作流质量 > 4.0/5.0，对话满意度 > 85%，成本降低 > 30%
- **用户**：AI 使用率 > 50%，生成时间 < 30 秒，NPS > 40

### 时间线
- **总时长**：2-3 周（18-23 天）
- **阶段数**：5 个阶段，35 个任务
- **关键里程碑**：Phase 1（核心服务）→ Phase 2（工作流优化）→ Phase 3（对话管理）→ Phase 4（AI Agent）→ Phase 5（测试发布）

## 相关文档

- [Claude API 文档](https://docs.anthropic.com/claude/reference)
- [AICodeWith 文档](https://docs.aicodewith.com/docs)
- [设计文档](design.md) - 详细技术设计
- [任务清单](tasks.md) - 35 个具体任务
- [现有 LLM 服务代码](packages/client/src/services/llmService.ts)
- [BPMN 编辑器提示词](packages/client/src/prompts/)
